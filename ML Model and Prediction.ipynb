{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Split data into Training and Test sets\n",
    "\n",
    "The first step in order to build our model for the Iris dataset, given that initial EDA did not indicate the need for further data preprocessing, is to split our dataset. We'll fit our model on the training set, and test it on the test set.  For this purpose we'll use scikit-learn's built-in \"train_test_split\" function. This function shuffles and splits our initial dataset into a training set with 75% of the samples, and a tess set with the remaining 30% of our observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: \n",
      "(112, 4)\n",
      "\n",
      "y_train shape: \n",
      "(112,)\n",
      "\n",
      "X_test shape: \n",
      "(38, 4)\n",
      "\n",
      "y_test shape: \n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \\n{}\".format(X_train.shape))\n",
    "print(\"\\n\" + \"y_train shape: \\n{}\".format(y_train.shape))\n",
    "print(\"\\n\" + \"X_test shape: \\n{}\".format(X_test.shape))\n",
    "print(\"\\n\" + \"y_test shape: \\n{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: \n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "X_test type: \n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "y_train type: \n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "y_test type: \n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train type: \\n{}\".format(type(X_train)))\n",
    "print(\"\\n\" + \"X_test type: \\n{}\".format(type(X_test)))\n",
    "print(\"\\n\" + \"y_train type: \\n{}\".format(type(y_train)))\n",
    "print(\"\\n\" + \"y_test type: \\n{}\".format(type(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Visualization\n",
    "\n",
    "Before blindly fitting models or any sophisticated machine learning technique, it's vital to inspect our data. This step may even show us that no modelling is necessary at all! Besides, abnormal measurements (outliers, missing data, or any other inconsistency) can be identified in this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create this scatter plot, first we need to keep in mind that numpy arrays are not the best option for data inspection and visualization. Therefore, we can convert these arrays into a Pandas DataFrame because its table format with labelled columns and row indexing is easier to manipulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
